{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d06c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5795578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, average_precision_score\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34008698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading dataset\n",
    "\n",
    "df = pd.read_csv(\"dataset/CollegeMsg.txt\", sep=\" \",names=['src','dst','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "765b376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the Dataset in Snapshots\n",
    "\n",
    "df1=df.iloc[0:11968]\n",
    "df2=df.iloc[11968:23935]\n",
    "df3=df.iloc[23935:35902]\n",
    "df4=df.iloc[35902:47869]\n",
    "df5=df.iloc[47869:]\n",
    "df2 = df2.reset_index(drop=True)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "df4 = df4.reset_index(drop=True)\n",
    "df5 = df5.reset_index(drop=True)\n",
    "\n",
    "#print(df1,df2,df3,df4,df5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e4eb0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#G\n",
    "G= nx.Graph()\n",
    "\n",
    "src= df['src']\n",
    "dst= df['dst']\n",
    "\n",
    "for i in range (src.size):\n",
    "        s=src[i]\n",
    "        d=dst[i]\n",
    "        G.add_edges_from([(s,d)])\n",
    "\n",
    "G_nodes= list(G.nodes())\n",
    "\n",
    "for i in range(src.size):\n",
    "    if src[i] in G_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G.add_node(src[i])\n",
    "\n",
    "for i in range(dst.size):\n",
    "    if dst[i] in G_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G.add_node(dst[i])\n",
    "        \n",
    "G_nodes= list(G.nodes())\n",
    "\n",
    "#nx.draw_networkx(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61f647a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#G1\n",
    "G1= nx.Graph()\n",
    "\n",
    "src1= df1['src']\n",
    "dst1= df1['dst']\n",
    "\n",
    "for i in range (src1.size):\n",
    "        s=src1[i]\n",
    "        d=dst1[i]\n",
    "        G1.add_edges_from([(s,d)])\n",
    "\n",
    "G1_nodes= list(G1.nodes())\n",
    "\n",
    "for i in range(src1.size):\n",
    "    if src1[i] in G1_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G1.add_node(src1[i])\n",
    "\n",
    "for i in range(dst1.size):\n",
    "    if dst1[i] in G1_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G1.add_node(dst1[i])\n",
    "        \n",
    "G1_nodes= list(G1.nodes())\n",
    "\n",
    "\n",
    "#nx.draw_networkx(G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e65aa94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#G2\n",
    "G2= nx.Graph()\n",
    "\n",
    "src2= df2['src']\n",
    "dst2= df2['dst']\n",
    "\n",
    "for i in range (src2.size):\n",
    "        s=src2[i]\n",
    "        d=dst2[i]\n",
    "        G2.add_edges_from([(s,d)])\n",
    "\n",
    "G2_nodes= list(G2.nodes())\n",
    "\n",
    "for i in range(src2.size):\n",
    "    if src2[i] in G2_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G2.add_node(src2[i])\n",
    "\n",
    "for i in range(dst2.size):\n",
    "    if dst2[i] in G2_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G2.add_node(dst2[i])\n",
    "        \n",
    "G2_nodes= list(G2.nodes())\n",
    "\n",
    "#nx.draw_networkx(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "643c0834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#G3\n",
    "G3= nx.Graph()\n",
    "\n",
    "src3= df3['src']\n",
    "dst3= df3['dst']\n",
    "\n",
    "for i in range (src3.size):\n",
    "        s=src3[i]\n",
    "        d=dst3[i]\n",
    "        G3.add_edges_from([(s,d)])\n",
    "\n",
    "G3_nodes= list(G3.nodes())\n",
    "\n",
    "for i in range(src3.size):\n",
    "    if src3[i] in G3_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G3.add_node(src3[i])\n",
    "\n",
    "for i in range(dst3.size):\n",
    "    if dst3[i] in G3_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G3.add_node(dst3[i])\n",
    "        \n",
    "G3_nodes= list(G3.nodes())\n",
    "\n",
    "#nx.draw_networkx(G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fdadb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#G4\n",
    "G4= nx.Graph()\n",
    "\n",
    "src4= df4['src']\n",
    "dst4= df4['dst']\n",
    "\n",
    "for i in range (src4.size):\n",
    "        s=src4[i]\n",
    "        d=dst4[i]\n",
    "        G4.add_edges_from([(s,d)])\n",
    "\n",
    "G4_nodes= list(G4.nodes())\n",
    "\n",
    "for i in range(src4.size):\n",
    "    if src4[i] in G4_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G4.add_node(src4[i])\n",
    "\n",
    "for i in range(dst4.size):\n",
    "    if dst4[i] in G4_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G4.add_node(dst4[i])\n",
    "        \n",
    "G4_nodes= list(G4.nodes())\n",
    "\n",
    "#nx.draw_networkx(G4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfb111c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#G5\n",
    "G5= nx.Graph()\n",
    "\n",
    "src5= df5['src']\n",
    "dst5= df5['dst']\n",
    "\n",
    "for i in range (src5.size):\n",
    "        s=src5[i]\n",
    "        d=dst5[i]\n",
    "        G5.add_edges_from([(s,d)])\n",
    "\n",
    "G5_nodes= list(G5.nodes())\n",
    "\n",
    "for i in range(src5.size):\n",
    "    if src5[i] in G5_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G5.add_node(src5[i])\n",
    "\n",
    "for i in range(dst5.size):\n",
    "    if dst5[i] in G5_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G5.add_node(dst5[i])\n",
    "        \n",
    "G5_nodes= list(G5.nodes())\n",
    "\n",
    "\n",
    "#nx.draw_networkx(G5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d439038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding nodes from master graph to G5\n",
    "for i in range(len(G_nodes)):\n",
    "    if G_nodes[i] in G5_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G5.add_node(G_nodes[i])\n",
    "        \n",
    "G5_nodes= list(G5.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcddac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes: 1026\n",
      "Total edges: 2817\n",
      "Training edges (positive): 1972\n",
      "Training edges (negative): 1972\n",
      "Test edges (positive): 845\n",
      "Test edges (negative): 845\n"
     ]
    }
   ],
   "source": [
    "# Preparing Train and Test Datasets\n",
    "from gae.preprocessing import mask_test_edges\n",
    "np.random.seed(0) # make sure train-test split is consistent between notebooks\n",
    "\n",
    "adj_sparse = nx.to_scipy_sparse_matrix(G5)\n",
    "\n",
    "adj_train, train_edges, train_edges_false, val_edges, val_edges_false, \\\n",
    "    test_edges, test_edges_false = mask_test_edges(adj_sparse, test_frac=.3, val_frac=.0, prevent_disconnect = True)\n",
    "\n",
    "print (\"Total nodes:\", adj_sparse.shape[0])\n",
    "print (\"Total edges:\", int(adj_sparse.nnz/2)) # adj is symmetric, so nnz (num non-zero) = 2*num_edges\n",
    "print (\"Training edges (positive):\", len(train_edges))\n",
    "print (\"Training edges (negative):\", len(train_edges_false))\n",
    "print (\"Test edges (positive):\", len(test_edges))\n",
    "print (\"Test edges (negative):\", len(test_edges_false))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae1e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81793f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding all nodes to snapshot\n",
    "\n",
    "#G1\n",
    "for i in range(len(G_nodes)):\n",
    "    if G_nodes[i] in G1_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G1.add_node(G_nodes[i])\n",
    "        \n",
    "G1_nodes= list(G1.nodes())\n",
    "\n",
    "#G2\n",
    "for i in range(len(G_nodes)):\n",
    "    if G_nodes[i] in G2_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G2.add_node(G_nodes[i])\n",
    "        \n",
    "G2_nodes= list(G2.nodes())\n",
    "\n",
    "#G3\n",
    "for i in range(len(G_nodes)):\n",
    "    if G_nodes[i] in G3_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G3.add_node(G_nodes[i])\n",
    "        \n",
    "G3_nodes= list(G3.nodes())\n",
    "\n",
    "#G4\n",
    "for i in range(len(G_nodes)):\n",
    "    if G_nodes[i] in G4_nodes:\n",
    "        continue\n",
    "    else:\n",
    "        G4.add_node(G_nodes[i])\n",
    "        \n",
    "G4_nodes= list(G4.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f43fc91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Removing test edges from Snapshots\n",
    "\n",
    "#G1\n",
    "\n",
    "G1_edges=G1.edges()\n",
    "\n",
    "for i in range(len(test_edges)):\n",
    "    if test_edges[i] in G1_edges:\n",
    "        G1.remove_edge(*test_edges[i])\n",
    "\n",
    "\n",
    " #G2\n",
    "    \n",
    "G2_edges=G2.edges()\n",
    "\n",
    "\n",
    "for i in range(len(test_edges)):\n",
    "    if test_edges[i] in G2_edges:\n",
    "        G2.remove_edge(*test_edges[i])\n",
    "\n",
    "\n",
    "#G3\n",
    "\n",
    "G3_edges=G3.edges()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(test_edges)):\n",
    "    if test_edges[i] in G3_edges:\n",
    "        G3.remove_edge(*test_edges[i])\n",
    "\n",
    "#G4\n",
    "\n",
    "G4_edges=G4.edges()\n",
    "\n",
    "for i in range(len(test_edges)):\n",
    "    if test_edges[i] in G4_edges:\n",
    "        G4.remove_edge(*test_edges[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97581c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a1a0f229324fb9b42007fbacf5db0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/1899 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|███████████████████████████████████████████████████████| 12/12 [00:04<00:00,  2.46it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a805737ddbd4d7ba0655b14093f6823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/1899 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|███████████████████████████████████████████████████████| 12/12 [00:05<00:00,  2.36it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7db938f1ea4b18ac74bae95c317986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/1899 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|███████████████████████████████████████████████████████| 12/12 [00:05<00:00,  2.29it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a591168cbbfb442090e7a9aac9fcfe03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/1899 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|███████████████████████████████████████████████████████| 12/12 [00:05<00:00,  2.12it/s]\n"
     ]
    }
   ],
   "source": [
    "#Getting node embeddings\n",
    "\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "#G1\n",
    "node2vec_1 = Node2Vec(G1, dimensions=128, walk_length=80, num_walks=12)\n",
    "n2v_model_1 = node2vec_1.fit(window=10, min_count=1)\n",
    "\n",
    "#G2\n",
    "node2vec_2 = Node2Vec(G2, dimensions=128, walk_length=80, num_walks=12)\n",
    "n2v_model_2 = node2vec_2.fit(window=10, min_count=1)\n",
    "\n",
    "#G3\n",
    "node2vec_3 = Node2Vec(G3, dimensions=128, walk_length=80, num_walks=12)\n",
    "n2v_model_3 = node2vec_3.fit(window=10, min_count=1)\n",
    "\n",
    "#G4\n",
    "node2vec_4 = Node2Vec(G4, dimensions=128, walk_length=80, num_walks=12)\n",
    "n2v_model_4 = node2vec_4.fit(window=10, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeebe6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting edge embeddings\n",
    "\n",
    "def get_edge_embeddings(edge_list,n2v_model):\n",
    "    embs = []\n",
    "    for edge in edge_list:\n",
    "        node1 = edge[0]\n",
    "        node2 = edge[1]\n",
    "        emb1 = n2v_model.wv[node1]\n",
    "        emb2 = n2v_model.wv[node2]\n",
    "        edge_emb = np.add(emb1, emb2)\n",
    "        embs.append(edge_emb)\n",
    "    embs = np.array(embs)\n",
    "    return embs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8294b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train dataset\n",
    "\n",
    "#Positive\n",
    "\n",
    "pos_train_embs_1= get_edge_embeddings(train_edges,n2v_model_1)\n",
    "pos_train_embs_2= get_edge_embeddings(train_edges,n2v_model_2)\n",
    "pos_train_embs_3= get_edge_embeddings(train_edges,n2v_model_3)\n",
    "pos_train_embs_4= get_edge_embeddings(train_edges,n2v_model_4)\n",
    "\n",
    "#Negative\n",
    "\n",
    "neg_train_embs_1= get_edge_embeddings(train_edges_false,n2v_model_1)\n",
    "neg_train_embs_2= get_edge_embeddings(train_edges_false,n2v_model_2)\n",
    "neg_train_embs_3= get_edge_embeddings(train_edges_false,n2v_model_3)\n",
    "neg_train_embs_4= get_edge_embeddings(train_edges_false,n2v_model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9120556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test dataset\n",
    "\n",
    "#Positive\n",
    "\n",
    "pos_test_embs_1= get_edge_embeddings(test_edges,n2v_model_1)\n",
    "pos_test_embs_2= get_edge_embeddings(test_edges,n2v_model_2)\n",
    "pos_test_embs_3= get_edge_embeddings(test_edges,n2v_model_3)\n",
    "pos_test_embs_4= get_edge_embeddings(test_edges,n2v_model_4)\n",
    "\n",
    "#Negative\n",
    "\n",
    "neg_test_embs_1= get_edge_embeddings(test_edges_false,n2v_model_1)\n",
    "neg_test_embs_2= get_edge_embeddings(test_edges_false,n2v_model_2)\n",
    "neg_test_embs_3= get_edge_embeddings(test_edges_false,n2v_model_3)\n",
    "neg_test_embs_4= get_edge_embeddings(test_edges_false,n2v_model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "968b4e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Dataset\n",
    "train_edges_emb_1=np.hstack([pos_train_embs_1,pos_train_embs_2,pos_train_embs_3,pos_train_embs_4])\n",
    "train_edges_label_1=np.ones(len(train_edges))\n",
    "train_edges_emb_2=np.hstack([neg_train_embs_1,neg_train_embs_2,neg_train_embs_3,neg_train_embs_4])\n",
    "train_edges_label_2=np.zeros(len(train_edges_false))\n",
    "\n",
    "train_edges_label= np.concatenate([train_edges_label_1,train_edges_label_2])\n",
    "train_edges_emb= np.concatenate([train_edges_emb_1,train_edges_emb_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3cab550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Dataset\n",
    "test_edges_emb_1=np.hstack([pos_test_embs_1,pos_test_embs_2,pos_test_embs_3,pos_test_embs_4])\n",
    "test_edges_label_1=np.ones(len(test_edges))\n",
    "test_edges_emb_2=np.hstack([neg_test_embs_1,neg_test_embs_2,neg_test_embs_3,neg_test_embs_4])\n",
    "test_edges_label_2=np.zeros(len(test_edges_false))\n",
    "\n",
    "test_edges_label= np.concatenate([test_edges_label_1,test_edges_label_2])\n",
    "test_edges_emb= np.concatenate([test_edges_emb_1,test_edges_emb_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72a461af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9424347886978748\n",
      "0.9189273499849676\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression classifier on train-set edge embeddings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "edge_classifier = LogisticRegression(max_iter=3000,random_state=0)\n",
    "edge_classifier.fit(train_edges_emb, train_edges_label)\n",
    "\n",
    "# Predicted edge scores: probability of being of class \"1\" (real edge)\n",
    "test_preds = edge_classifier.predict_proba(test_edges_emb)[:, 1]\n",
    "test_roc = roc_auc_score(test_edges_label, test_preds)\n",
    "test_ap = average_precision_score(test_edges_label, test_preds)\n",
    "print(test_roc)\n",
    "print(test_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e2de4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9397226987850565\n",
      "0.9206430494644313\n"
     ]
    }
   ],
   "source": [
    "edge_classifier_1= RandomForestClassifier(n_estimators = 50)\n",
    "edge_classifier_1.fit(train_edges_emb, train_edges_label)\n",
    "\n",
    "test_preds_1 = edge_classifier_1.predict_proba(test_edges_emb)[:, 1]\n",
    "test_roc_1 = roc_auc_score(test_edges_label, test_preds_1)\n",
    "test_ap_1 = average_precision_score(test_edges_label, test_preds_1)\n",
    "\n",
    "print(test_roc_1)\n",
    "print(test_ap_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf804ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9343846503973952\n",
      "0.9140562452920873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "edge_classifier_2 = GradientBoostingClassifier(n_estimators=50, learning_rate=0.5, max_depth=8, random_state=0).fit(train_edges_emb, train_edges_label)\n",
    "edge_classifier_2 = GradientBoostingClassifier(n_estimators=50, learning_rate=0.5, max_depth=8, random_state=0).fit(train_edges_emb, train_edges_label)\n",
    "\n",
    "test_preds_2 = edge_classifier_2.predict_proba(test_edges_emb)[:, 1]\n",
    "test_roc_2 = roc_auc_score(test_edges_label, test_preds_2)\n",
    "test_ap_2 = average_precision_score(test_edges_label, test_preds_2)\n",
    "\n",
    "print(test_roc_2)\n",
    "print(test_ap_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bd87313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Train XGBoost classifier on train-set edge embeddings\n",
    "\n",
    "# import xgboost as xgb\n",
    "\n",
    "# xgb_cl = xgb.XGBClassifier()\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# xgb_cl = xgb.XGBClassifier()\n",
    "# xgb_cl.fit(train_edges_emb,train_edges_label)\n",
    "# preds = xgb_cl.predict(test_edges_emb)\n",
    "\n",
    "# print(accuracy_score(test_edges_label, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4327940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Train Random Forest classifier on train-set edge embeddings\n",
    "\n",
    "# #classifier\n",
    "# clf1 = RandomForestClassifier()\n",
    " \n",
    "# # parameters\n",
    "# param = {'n_estimators' : [10,50,100], 'max_depth' : [5,10,15]}\n",
    " \n",
    "# # model\n",
    "# grid_clf_acc1 = GridSearchCV(clf1, param_grid = param)\n",
    " \n",
    "# # train the model\n",
    "# grid_clf_acc1.fit(train_edges_emb,train_edges_label)\n",
    " \n",
    "# print('Grid best parameter (max. accuracy): ', grid_clf_acc1.best_params_)\n",
    "# print('Grid best score (accuracy): ', grid_clf_acc1.best_score_)\n",
    " \n",
    "# # alternative metric to optimize over grid parameters: AUC\n",
    "# grid_clf_auc1 = GridSearchCV(clf1, param_grid = param, scoring = 'roc_auc')\n",
    "# grid_clf_auc1.fit(train_edges_emb,train_edges_label)\n",
    "# predict_proba = grid_clf_auc1.predict_proba(test_edges_emb)[:,1]\n",
    " \n",
    "# print('Test set AUC: ', roc_auc_score(test_edges_label, predict_proba))\n",
    "# print('Grid best parameter (max. AUC): ', grid_clf_auc1.best_params_)\n",
    "# print('Grid best score (AUC): ', grid_clf_auc1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b10ba156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Train Gradient Boost classifier on train-set edge embeddings\n",
    "\n",
    "# # classifier\n",
    "# clf2 = GradientBoostingClassifier()\n",
    " \n",
    "# # parameters\n",
    "# param = {'learning_rate' : [.05,.1]}\n",
    " \n",
    "# # model\n",
    "# grid_clf_acc2 = GridSearchCV(clf2, param_grid = param)\n",
    " \n",
    "# # train the model\n",
    "# grid_clf_acc2.fit(train_edges_emb,train_edges_label)\n",
    " \n",
    "# print('Grid best parameter (max. accuracy): ', grid_clf_acc2.best_params_)\n",
    "# print('Grid best score (accuracy): ', grid_clf_acc2.best_score_)\n",
    " \n",
    "# # alternative metric to optimize over grid parameters: AUC\n",
    "# grid_clf_auc2 = GridSearchCV(clf2, param_grid = param, scoring = 'roc_auc')\n",
    "# grid_clf_auc2.fit(train_edges_emb,train_edges_label)\n",
    "# predict_proba = grid_clf_auc2.predict_proba(test_edges_emb)[:,1]\n",
    " \n",
    "# print('Test set AUC: ', roc_auc_score(test_edges_label, predict_proba))\n",
    "# print('Grid best parameter (max. AUC): ', grid_clf_auc2.best_params_)\n",
    "# print('Grid best score (AUC): ', grid_clf_auc2.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208d648f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
